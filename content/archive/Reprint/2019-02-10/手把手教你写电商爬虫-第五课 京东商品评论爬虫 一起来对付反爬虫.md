---
title: '手把手教你写电商爬虫-第五课 京东商品评论爬虫 一起来对付反爬虫' 
date: 2019-02-10 2:30:42
hidden: true
slug: qywsb1h24df
categories: [reprint]
---

{{< raw >}}

                    
<p>系列教程：</p>
<p><a href="https://segmentfault.com/a/1190000005116394">手把手教你写电商爬虫-第一课 找个软柿子捏捏</a></p>
<p><a href="https://segmentfault.com/a/1190000005133842" target="_blank">手把手教你写电商爬虫-第二课 实战尚妆网分页商品采集爬虫</a></p>
<p><a href="https://segmentfault.com/a/1190000005134077">手把手教你写电商爬虫-第三课 实战尚妆网AJAX请求处理和内容提取</a></p>
<p><a href="https://segmentfault.com/a/1190000005134609" target="_blank">手把手教你写电商爬虫-第四课 淘宝网商品爬虫自动JS渲染</a></p>
<p>四节课过去了，咱们在爬虫界也都算见过世面的人，现在再来一些什么ajax加载之类的小鱼小虾应该不在话下了，即使是淘宝这种大量的ajax，我们祭上我们的核武器，也轻松应对了，这一课主要是来看看除了技术上的页面处理外，我们还会遇上更棘手的问题，就是反爬虫，当然现在有各种各样的反爬虫，今天就先介绍最简单的一种：限制IP。</p>
<p>今天咱们的对手依然是业界大佬，马云最忌惮的男人，宅男心中爱恨交错的对象 - JD.COM</p>
<p>也不用我安利，特别是程序员，有几个没给京东送过钱的。废话不多说，先上工具：</p>
<p><strong>1、神箭手云爬虫，2、Chrome浏览器 3、Chrome的插件XpathHelper 不知道是干嘛的同学请移步第一课</strong></p>
<p>打开网站瞅一眼：</p>
<p><span class="img-wrap"><img data-src="/img/bVvHWS" src="https://static.alili.tech/img/bVvHWS" alt="图片描述" title="图片描述" style="cursor: pointer; display: inline;"></span></p>
<p>好了，相信我，截这张图绝对不是在虐你们这些单身狗。我们就是科学的研究一下这个页面，没啥特别的：大厂风，硬仗准备。</p>
<p>先来挑一个分类吧，这次挑一个大家都熟悉的互联网书类：</p>
<div class="widget-codetool" style="display:none;">
      <div class="widget-codetool--inner">
      <span class="selectCode code-tool" data-toggle="tooltip" data-placement="top" title="" data-original-title="全选"></span>
      <span type="button" class="copyCode code-tool" data-toggle="tooltip" data-placement="top" data-clipboard-text="http://search.jd.com/Search?keyword=Python&amp;enc=utf-8&amp;book=y&amp;wq=Python&amp;pvid=33xo9lni.p4a1qb
" title="" data-original-title="复制"></span>
      <span type="button" class="saveToNote code-tool" data-toggle="tooltip" data-placement="top" title="" data-original-title="放进笔记"></span>
      </div>
      </div><pre class="hljs vim"><code>http://<span class="hljs-built_in">search</span>.jd.<span class="hljs-keyword">com</span>/Search?keyword=Python&amp;enc=utf-<span class="hljs-number">8</span>&amp;book=<span class="hljs-keyword">y</span>&amp;<span class="hljs-keyword">wq</span>=Python&amp;pvid=<span class="hljs-number">33</span>xo9lni.p4a1qb
</code></pre>
<p>你们的最爱，python从入门到放弃的全部资料。</p>
<p>和前面几节课类似的分析这节课就不做了，对于分页，ajax请求什么的，大家可以直接参考前面的四节课，这一刻主要特别的是，我们在采集商品的同时，会将京东的商品评价采集下来。同时呢，我们也探讨下该如何应对京东对IP的限制，OK，先直接上代码：</p>
<div class="widget-codetool" style="display:none;">
      <div class="widget-codetool--inner">
      <span class="selectCode code-tool" data-toggle="tooltip" data-placement="top" title="" data-original-title="全选"></span>
      <span type="button" class="copyCode code-tool" data-toggle="tooltip" data-placement="top" data-clipboard-text="var configs = {  
    domains: [&quot;search.jd.com&quot;,&quot;item.jd.com&quot;,&quot;club.jd.com&quot;],  
    scanUrls: [&quot;http://search.jd.com/Search?keyword=Python&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;book=y&amp;vt=2&amp;page=1&amp;s=1&amp;click=0&quot;],  
    contentUrlRegexes: [&quot;http://item\\.jd\\.com/\\d+.html&quot;],  
    helperUrlRegexes: [&quot;http://search\\.jd\\.com/Search\\?keyword=Python&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;book=y&amp;vt=2&amp;page=\\d+&amp;s=1&amp;click=0&quot;],//可留空  
    fields: [  
        {  
            // 第一个抽取项  
            name: &quot;title&quot;,  
            selector: &quot;//div[@id='name']/h1&quot;,//默认使用XPath  
            required: true //是否不能为空  
        },  
        {  
            // 第一个抽取项  
            name: &quot;productid&quot;,  
            selector: &quot;//div[contains(@class,'fl')]/span[2]&quot;,//默认使用XPath  
            required: true //是否不能为空  
        },  
        {  
            name: &quot;comments&quot;,  
            sourceType: SourceType.AttachedUrl,  
            attachedUrl: &quot;http://club.jd.com/productpage/p-{productid}-s-0-t-3-p-0.html&quot;,  
            selectorType: SelectorType.JsonPath,  
            selector: &quot;$.comments&quot;,  
            repeated: true,  
            children:[  
                {  
                    name: &quot;com_content&quot;,  
                    selectorType: SelectorType.JsonPath,  
                    selector: &quot;$.content&quot;  
                },  
                {  
                    name: &quot;com_nickname&quot;,  
                    selectorType: SelectorType.JsonPath,  
                    selector: &quot;$.nickname&quot;  
                },  
            ]  
        }  
    ]  
};  
configs.onProcessHelperUrl = function(url, content, site){  
    if(!content.indexOf(&quot;抱歉，没有找到&quot;)){  
        var currentPage = parseInt(url.substring(url.indexOf(&quot;&amp;page=&quot;) + 6));  
        if(currentPage == 0){  
            currentPage = 1;  
        }  
        var page = currentPage + 2;  
        var nextUrl = url.replace(&quot;&amp;page=&quot; + currentPage, &quot;&amp;page=&quot; + page);  
        site.addUrl(nextUrl);  
    }  
    return true;  
};  
var crawler = new Crawler(configs);  
crawler.start();  
" title="" data-original-title="复制"></span>
      <span type="button" class="saveToNote code-tool" data-toggle="tooltip" data-placement="top" title="" data-original-title="放进笔记"></span>
      </div>
      </div><pre class="hljs dts"><code>var configs = {  
<span class="hljs-symbol">    domains:</span> [<span class="hljs-string">"search.jd.com"</span>,<span class="hljs-string">"item.jd.com"</span>,<span class="hljs-string">"club.jd.com"</span>],  
<span class="hljs-symbol">    scanUrls:</span> [<span class="hljs-string">"http://search.jd.com/Search?keyword=Python&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;book=y&amp;vt=2&amp;page=1&amp;s=1&amp;click=0"</span>],  
<span class="hljs-symbol">    contentUrlRegexes:</span> [<span class="hljs-string">"http://item\\.jd\\.com/\\d+.html"</span>],  
<span class="hljs-symbol">    helperUrlRegexes:</span> [<span class="hljs-string">"http://search\\.jd\\.com/Search\\?keyword=Python&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;book=y&amp;vt=2&amp;page=\\d+&amp;s=1&amp;click=0"</span>],<span class="hljs-comment">//可留空  </span>
<span class="hljs-symbol">    fields:</span> [  
        {  
            <span class="hljs-comment">// 第一个抽取项  </span>
<span class="hljs-symbol">            name:</span> <span class="hljs-string">"title"</span>,  
<span class="hljs-symbol">            selector:</span> <span class="hljs-string">"//div[@id='name']/h1"</span>,<span class="hljs-comment">//默认使用XPath  </span>
<span class="hljs-symbol">            required:</span> true <span class="hljs-comment">//是否不能为空  </span>
        },  
        {  
            <span class="hljs-comment">// 第一个抽取项  </span>
<span class="hljs-symbol">            name:</span> <span class="hljs-string">"productid"</span>,  
<span class="hljs-symbol">            selector:</span> <span class="hljs-string">"//div[contains(@class,'fl')]/span[2]"</span>,<span class="hljs-comment">//默认使用XPath  </span>
<span class="hljs-symbol">            required:</span> true <span class="hljs-comment">//是否不能为空  </span>
        },  
        {  
<span class="hljs-symbol">            name:</span> <span class="hljs-string">"comments"</span>,  
<span class="hljs-symbol">            sourceType:</span> SourceType.AttachedUrl,  
<span class="hljs-symbol">            attachedUrl:</span> <span class="hljs-string">"http://club.jd.com/productpage/p-{productid}-s-0-t-3-p-0.html"</span>,  
<span class="hljs-symbol">            selectorType:</span> SelectorType.JsonPath,  
<span class="hljs-symbol">            selector:</span> <span class="hljs-string">"$.comments"</span>,  
<span class="hljs-symbol">            repeated:</span> true,  
<span class="hljs-symbol">            children:</span>[  
                {  
<span class="hljs-symbol">                    name:</span> <span class="hljs-string">"com_content"</span>,  
<span class="hljs-symbol">                    selectorType:</span> SelectorType.JsonPath,  
<span class="hljs-symbol">                    selector:</span> <span class="hljs-string">"$.content"</span>  
                },  
                {  
<span class="hljs-symbol">                    name:</span> <span class="hljs-string">"com_nickname"</span>,  
<span class="hljs-symbol">                    selectorType:</span> SelectorType.JsonPath,  
<span class="hljs-symbol">                    selector:</span> <span class="hljs-string">"$.nickname"</span>  
                },  
            ]  
        }  
    ]  
};  
configs.onProcessHelperUrl = function(url, content, site){  
    if(!content.indexOf(<span class="hljs-string">"抱歉，没有找到"</span>)){  
        var currentPage = parseInt(url.substring(url.indexOf(<span class="hljs-string">"&amp;page="</span>) + <span class="hljs-number">6</span>));  
        if(currentPage == <span class="hljs-number">0</span>){  
            currentPage = <span class="hljs-number">1</span>;  
        }  
        var page = currentPage + <span class="hljs-number">2</span>;  
        var nextUrl = url.replace(<span class="hljs-string">"&amp;page="</span> + currentPage, <span class="hljs-string">"&amp;page="</span> + page);  
        site.addUrl(nextUrl);  
    }  
    return true;  
};  
var crawler = new Crawler(configs);  
crawler.start();  
</code></pre>
<p>这里主要给大家讲一下这个评论的配置，由于评论是多项，且评论还有子项，在框架中，是通过children关键字来配置的。具体参照代码既可，我们可以在子项中在定义不同的字段，像这里的comments抽取项会有content和nickname两个子抽取项，分别对应的是评论的内容和昵称。</p>
<p>这里是一个简化的版本，由于京东页面相对很复杂，我们在抽取评论的时候，只抽取前一部分评论，当然我们还可以拿到更多的信息，包括评论数，评论人的等级等等，这里大家就自行探索吧。</p>
<p>最后，由于京东会对IP进行封锁，虽然说神箭手会自动分布式开启爬虫，不过依然扛不住京东大叔的封锁，因此这里需要通过接入代理IP解决这样的问题，类似开启js渲染，爬取速度会大大下降，需要大家耐心等待结果喽，代码如下：</p>
<div class="widget-codetool" style="display:none;">
      <div class="widget-codetool--inner">
      <span class="selectCode code-tool" data-toggle="tooltip" data-placement="top" title="" data-original-title="全选"></span>
      <span type="button" class="copyCode code-tool" data-toggle="tooltip" data-placement="top" data-clipboard-text="configs.enableProxy = true;  
" title="" data-original-title="复制"></span>
      <span type="button" class="saveToNote code-tool" data-toggle="tooltip" data-placement="top" title="" data-original-title="放进笔记"></span>
      </div>
      </div><pre class="hljs nix"><code>configs.<span class="hljs-attr">enableProxy</span> = <span class="hljs-literal">true</span>;  
</code></pre>
<p>大功告成，开启爬虫，喝杯咖啡，京东商品的评论就可以看到啦：</p>
<p><span class="img-wrap"><img data-src="/img/bVvHWu" src="https://static.alili.tech/img/bVvHWu" alt="图片描述" title="图片描述" style="cursor: pointer; display: inline;"></span></p>
<p>评论因为是数字，因此会存储的时候，会直接存储成json格式：</p>
<p><span class="img-wrap"><img data-src="/img/bVvHWw" src="https://static.alili.tech/img/bVvHWw" alt="图片描述" title="图片描述" style="cursor: pointer; display: inline;"></span></p>
<p>对爬虫感兴趣的童鞋可以加qq群讨论：342953471。</p>

                
{{< /raw >}}

# 版权声明
本文资源来源互联网，仅供学习研究使用，版权归该资源的合法拥有者所有，

本文仅用于学习、研究和交流目的。转载请注明出处、完整链接以及原作者。

原作者若认为本站侵犯了您的版权，请联系我们，我们会立即删除！

## 原文标题
手把手教你写电商爬虫-第五课 京东商品评论爬虫 一起来对付反爬虫

## 原文链接
[https://segmentfault.com/a/1190000005134770](https://segmentfault.com/a/1190000005134770)

